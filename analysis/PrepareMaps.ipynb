{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare maps for analysis\n",
    "- convert to z map\n",
    "- check MNI space\n",
    "\n",
    "Hypotheses:\n",
    "\n",
    "Parametric effect of gain:\n",
    "\n",
    "1. Positive effect in ventromedial PFC - for the equal indifference group\n",
    "2. Positive effect in ventromedial PFC - for the equal range group\n",
    "3. Positive effect in ventral striatum - for the equal indifference group\n",
    "4. Positive effect in ventral striatum - for the equal range group\n",
    "\n",
    "Parametric effect of loss:\n",
    "- 5: Negative effect in VMPFC - for the equal indifference group\n",
    "- 6: Negative effect in VMPFC - for the equal range group\n",
    "- 7: Positive effect in amygdala - for the equal indifference group\n",
    "- 8: Positive effect in amygdala - for the equal range group\n",
    "\n",
    "Equal range vs. equal indifference:\n",
    "\n",
    "- 9: Greater positive response to losses in amygdala for equal range condition vs. equal indifference condition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy,pandas\n",
    "import nibabel\n",
    "import json\n",
    "import os,glob\n",
    "import nilearn.image\n",
    "import nilearn.input_data\n",
    "import nilearn.plotting\n",
    "from collections import OrderedDict\n",
    "import shutil\n",
    "import warnings\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "hypotheses= {1:'+gain: equal indiff',\n",
    "            2:'+gain: equal range',\n",
    "            3:'+gain: equal indiff',\n",
    "            4:'+gain: equal range',\n",
    "            5:'-loss: equal indiff',\n",
    "            6:'-loss: equal range',\n",
    "            7:'+loss: equal indiff',\n",
    "            8:'+loss: equal range',\n",
    "            9:'+loss:ER>EI'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to import duecredit due to No module named 'duecredit'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/poldrack/.cache/templateflow/tpl-MNI152NLin2009cAsym/tpl-MNI152NLin2009cAsym_from-MNI152NLin6Asym_mode-image_xfm.h5')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from templateflow.api import get\n",
    "get('MNI152NLin2009cAsym', **{'from': 'MNI152NLin6Asym'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading the metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 39)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_file = '/Users/poldrack/data_unsynced/NARPS/analysis_pipelines.xlsx'\n",
    "metadata = pandas.read_excel(metadata_file,header=1)\n",
    "metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['teamID', 'NV_collection_string', 'results_comments', 'preregistered',\n",
       "       'link_preregistration_form', 'regions_definition', 'softwares',\n",
       "       'n_participants', 'exclusions_details', 'used_fmriprep_data',\n",
       "       'preprocessing_order', 'brain_extraction', 'segmentation',\n",
       "       'slice_time_correction', 'motion_correction',\n",
       "       'gradient_distortion_correction', 'intra_subject_coreg',\n",
       "       'distortion_correction', 'inter_subject_reg', 'intensity_correction',\n",
       "       'intensity_normalization', 'noise_removal', 'volume_censoring',\n",
       "       'spatial_smoothing', 'preprocessing_comments',\n",
       "       'data_submitted_to_model', 'spatial_region_modeled',\n",
       "       'independent_vars_first_level', 'independent_vars_higher_level',\n",
       "       'model_type', 'model_settings', 'inference_contrast_effect',\n",
       "       'search_region', 'statistic_type', 'pval_computation',\n",
       "       'multiple_testing_correction', 'comments_analysis', 'general comments',\n",
       "       'additional files?'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the statistical images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 57 input directories\n"
     ]
    }
   ],
   "source": [
    "orig_dir = '/Users/poldrack/data_unsynced/NARPS/maps/orig'\n",
    "output_dir = '/Users/poldrack/data_unsynced/NARPS/maps'\n",
    "\n",
    "input_jsons = glob.glob(os.path.join(orig_dir,'*/images.json'))\n",
    "print('found',len(input_jsons),'input directories')\n",
    "input_dirs = [os.path.dirname(i) for i in input_jsons]\n",
    "mask_img = os.path.join(output_dir,'templates/MNI152_T1_2mm_brain_mask.nii.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh : found  60 datasets\n",
      "unthresh : found  60 datasets\n"
     ]
    }
   ],
   "source": [
    "# find maps\n",
    "imgfile_dict = {'thresh':{},'unthresh':{}}\n",
    "\n",
    "for i in input_dirs:\n",
    "    for h in range(1,10):\n",
    "        for t in ['thresh','unthresh']:\n",
    "            fname=os.path.join(i,'hypo%d_%s.nii.gz'%(h,t))\n",
    "            if os.path.exists(fname):\n",
    "                if not i in imgfile_dict[t]:\n",
    "                    imgfile_dict[t][i]={}\n",
    "                imgfile_dict[t][i][h]=fname\n",
    "    if i in imgfile_dict['thresh']:\n",
    "        if not len(imgfile_dict['thresh'][i])==9:\n",
    "            print(\"missing files for\",i,': only',len(imgfile_dict['thresh'][i]),'found')\n",
    "            del imgfile_dict['thresh'][i]\n",
    "    if i in imgfile_dict['unthresh']:\n",
    "        if not len(imgfile_dict['unthresh'][i])==9:\n",
    "            print(\"missing files for\",i,': only',len(imgfile_dict['unthresh'][i]),'found')\n",
    "            del imgfile_dict['unthresh'][i]\n",
    "for t in ['thresh','unthresh']:\n",
    "    print(t,': found ',len(imgfile_dict[t]),'datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resample into FSL MNI space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YZFBWTVU_Q6O0 :converting to FSL MNI space\n",
      "FKMCNBTL_B5I6 :converting to FSL MNI space\n",
      "CLTGPQPO_43FJ :converting to FSL MNI space\n",
      "MQKTVNIH_08MQ :converting to FSL MNI space\n",
      "RIIVGRDK_E3B6 :converting to FSL MNI space\n",
      "YGVUUZDV_IZ20 :converting to FSL MNI space\n",
      "JAWCZRDS_V55J :converting to FSL MNI space\n",
      "MNASBORM_3PQ2 :converting to FSL MNI space\n",
      "NPZYAJUF_94GU :converting to FSL MNI space\n",
      "IZREEBAR_T54A :converting to FSL MNI space\n",
      "CMGDLXNE_C22U :converting to FSL MNI space\n",
      "COXUJKNY_R9K3 :converting to FSL MNI space\n",
      "ZNLBVOZG_UK24 :converting to FSL MNI space\n",
      "PVRJCPGN_X19V :converting to FSL MNI space\n",
      "XTQTYBTF_0I4U :converting to FSL MNI space\n",
      "QDWZHJWT_L7J7 :converting to FSL MNI space\n",
      "PJLEEUYF_46CD :converting to FSL MNI space\n",
      "CQCJIRXE_O03M :converting to FSL MNI space\n",
      "WLJQPTCD_O6R6 :converting to FSL MNI space\n",
      "LASLHJJB_I52Y :converting to FSL MNI space\n",
      "WRZSQULI_B23O :converting to FSL MNI space\n",
      "FLSSDFOD_9T8E :converting to FSL MNI space\n",
      "QJVDBBPV_R42Q :converting to FSL MNI space\n",
      "YWGVKXBZ_6FH5 :converting to FSL MNI space\n",
      "QTIWKLGM_O21U :converting to FSL MNI space\n",
      "UOELUJTL_1P0Y :converting to FSL MNI space\n",
      "IYQMMKMM_UI76 :converting to FSL MNI space\n",
      "DLIKXMQO_3TR7 :converting to FSL MNI space\n",
      "LNYOVSMV_50GV :converting to FSL MNI space\n",
      "LSGXYMCM_27SS :converting to FSL MNI space\n",
      "MNWEYQKT_9U7M :converting to FSL MNI space\n",
      "ZFFBNRMO_51PW :converting to FSL MNI space\n",
      "RJXZOPQC_1KB2 :converting to FSL MNI space\n",
      "ADFZYYLQ_C88N :converting to FSL MNI space\n",
      "PPCCKOJA_0JO0 :converting to FSL MNI space\n",
      "HDZTOPFX_XU70 :converting to FSL MNI space\n",
      "EPBGXICO_I07H :converting to FSL MNI space\n",
      "BEWWYWBV_5G9K :converting to FSL MNI space\n",
      "LOMXBZWB_U26C :converting to FSL MNI space\n",
      "MBCQRMVG_J7F9 :converting to FSL MNI space\n",
      "YBXXQPUZ_16IN :converting to FSL MNI space\n",
      "CGGOUIDK_X1Y5 :converting to FSL MNI space\n",
      "TBTGUAIJ_R7D1 :converting to FSL MNI space\n",
      "SMVTKIXZ_0ED6 :converting to FSL MNI space\n",
      "YNAABMIO_VG39 :converting to FSL MNI space\n",
      "NAOARURV_DC61 :converting to FSL MNI space\n",
      "VLFBNIQL_E6R3 :converting to FSL MNI space\n",
      "NUJQNDED_L9G5 :converting to FSL MNI space\n",
      "HQPUDNQU_K9P0 :converting to FSL MNI space\n",
      "JGNYNCRJ_80GC :converting to FSL MNI space\n",
      "ZUSVIGUS_SM54 :converting to FSL MNI space\n",
      "EDFRMJVJ_9Q6R :converting to FSL MNI space\n",
      "IKOFVLWN_I9D6 :converting to FSL MNI space\n",
      "CMJIFMMR_L3V8 :converting to FSL MNI space\n",
      "WYHPMBFA_2T6S :converting to FSL MNI space\n",
      "UXJVRRRR_0C7Q :converting to FSL MNI space\n",
      "TYOSOGDN_3C6G :converting to FSL MNI space\n",
      "UGXZBNJS_AO86 :converting to FSL MNI space\n",
      "OXLAIRNK_Q58J :converting to FSL MNI space\n",
      "RWUMYGCX_6VV2 :converting to FSL MNI space\n",
      "missing proper images for:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_img = os.path.join(output_dir,'templates/MNI152_T1_2mm.nii.gz')\n",
    "\n",
    "missing_images = []\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    for i in input_dirs:\n",
    "        if not (i in imgfile_dict['thresh']) or not (i in imgfile_dict['unthresh']):\n",
    "            missing_images.append(i)\n",
    "            continue\n",
    "        if not (len(imgfile_dict['thresh'][i])==9) or not (len(imgfile_dict['unthresh'][i])==9):\n",
    "            missing_images.append(i)\n",
    "            continue\n",
    "        # convert all to FSL space\n",
    "        if 0:\n",
    "            print(os.path.basename(i),': copying fmriprep data directly')\n",
    "            target_dir=os.path.join(output_dir,'mnispace',os.path.basename(i))\n",
    "            if not os.path.exists(target_dir):\n",
    "                print('copying',i,'to',target_dir)\n",
    "                shutil.copytree(i,target_dir)\n",
    "        else:\n",
    "            print(os.path.basename(i),':converting to FSL MNI space')\n",
    "            outdir = i.replace('orig','resampled')\n",
    "            if not os.path.exists(outdir):\n",
    "                os.mkdir(outdir)\n",
    "            for img in glob.glob(os.path.join(i,'hyp*nii.gz')):\n",
    "                if os.path.basename(img).find('_thresh')>-1:\n",
    "                    interp='nearest'\n",
    "                else:\n",
    "                    interp='continuous'\n",
    "                resampled = nilearn.image.resample_to_img(img, template_img,\n",
    "                                                    interpolation=interp)\n",
    "                resampled.to_filename(os.path.join(outdir,os.path.basename(img)))\n",
    "\n",
    "print('missing proper images for:')\n",
    "[os.path.basename(i) for i in missing_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine thresholded images and create summary map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/poldrack/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: get_affine method is deprecated.\n",
      "Please use the ``img.affine`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypo 1: found 57 maps\n",
      "hypo 2: found 57 maps\n",
      "hypo 3: found 57 maps\n",
      "hypo 4: found 57 maps\n",
      "hypo 5: found 57 maps\n",
      "hypo 6: found 57 maps\n",
      "hypo 7: found 57 maps\n",
      "hypo 8: found 57 maps\n",
      "hypo 9: found 57 maps\n"
     ]
    }
   ],
   "source": [
    "# make full image mask\n",
    "full_mask_img = os.path.join(output_dir,'MNI152_all_voxels.nii.gz')\n",
    "\n",
    "if not os.path.exists(full_mask_img):\n",
    "    mi = nibabel.load(mask_img)\n",
    "    d = mi.get_data()\n",
    "    d = numpy.ones(d.shape)\n",
    "    full_mask = nibabel.Nifti1Image(d,affine = mi.affine)\n",
    "    full_mask.to_filename(full_mask_img)\n",
    "\n",
    "for hyp in range(1,10):\n",
    "    hmaps = glob.glob(os.path.join(output_dir,'resampled/*/hypo%d_thresh.nii.gz'%hyp))\n",
    "    print('hypo %d: found %d maps'%(hyp,len(hmaps)))\n",
    "    masker = nilearn.input_data.NiftiMasker(mask_img=full_mask_img)\n",
    "    concat_data = masker.fit_transform(hmaps)\n",
    "    concat_img = masker.inverse_transform(concat_data)\n",
    "    concat_img.to_filename(os.path.join(output_dir,'thresh_concat/hypo%d.nii.gz'%hyp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create overlap maps for thresholded maps\n",
    "\n",
    "for hyp in range(1,10):\n",
    "    concat_img=nibabel.load(os.path.join(output_dir,'thresh_concat/hypo%d.nii.gz'%hyp))\n",
    "    concat_data = concat_img.get_data()\n",
    "    concat_data = (concat_data>10e-6).astype('float')\n",
    "    concat_data = numpy.nan_to_num(concat_data)\n",
    "    concat_mean = numpy.mean(concat_data,3)\n",
    "    concat_mean_img = nibabel.Nifti1Image(concat_mean,affine=concat_img.header.get_best_affine())\n",
    "    concat_mean_img.to_filename(os.path.join(output_dir,'thresh_mean/hypo%d.nii.gz'%hyp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert all unthresholded images to Z stat images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 57 json files\n",
      "['T map']\n",
      "['T map']\n",
      "['parcellation', 'other']\n",
      "['T map']\n",
      "['ROI/mask', 'univariate-beta map', 'T map']\n",
      "['ROI/mask', 'T map']\n",
      "['T map']\n",
      "['other']\n",
      "['T map']\n",
      "['Z map', '1-P map (\"inverted\" probability)', 'other', 'univariate-beta map']\n",
      "['other']\n",
      "['T map']\n",
      "['parcellation', 'other', 'ROI/mask']\n",
      "['other']\n",
      "['parcellation', 'other']\n",
      "['other']\n",
      "['T map']\n",
      "['parcellation', 'other']\n",
      "['other']\n",
      "['other']\n",
      "['T map']\n",
      "['T map']\n",
      "['Z map']\n",
      "['Z map']\n",
      "['other', 'T map']\n",
      "['Z map']\n",
      "['parcellation', 'other']\n",
      "['Z map']\n",
      "['other']\n",
      "['Z map']\n",
      "['Z map', 'other', 'T map']\n",
      "['Z map']\n",
      "['parcellation', 'other']\n",
      "['parcellation', 'other']\n",
      "['other']\n",
      "['Z map']\n",
      "['parcellation', 'other']\n",
      "['T map']\n",
      "['other']\n",
      "['T map']\n",
      "['parcellation', 'other', 'ROI/mask']\n",
      "['T map']\n",
      "['parcellation', 'other']\n",
      "['parcellation', 'other']\n",
      "['T map']\n",
      "['other']\n",
      "['T map']\n",
      "['parcellation', 'other']\n",
      "['Z map']\n",
      "['other']\n",
      "['Z map', 'other', 'univariate-beta map']\n",
      "['other']\n",
      "['other']\n",
      "['parcellation', 'other']\n",
      "['univariate-beta map', 'T map']\n",
      "['parcellation', 'other']\n",
      "['Z map']\n"
     ]
    }
   ],
   "source": [
    "# load image info from json\n",
    "\n",
    "def get_map_types(j):\n",
    "    maptypes=[]\n",
    "    for img in j:\n",
    "        maptypes.append(img['map_type'])\n",
    "    return(list(set(maptypes)))\n",
    "\n",
    "def parse_json(j):\n",
    "    imgtype = {}\n",
    "    for img in j:\n",
    "        fname=os.path.basename(img['file']).replace('.nii.gz','')\n",
    "        print(fname)\n",
    "        f_s = fname.split('_')\n",
    "        try:\n",
    "            hypnum = int(f_s[0].replace('hypo',''))\n",
    "            imgtype = f_s[1]\n",
    "        except:\n",
    "            print(\"something went wrong\")\n",
    "        print(f_s)\n",
    "    return(imgtype)\n",
    "        \n",
    "\n",
    "jsonfiles = glob.glob(os.path.join(orig_dir,'*/images.json'))\n",
    "print(\"found %d json files\"%len(jsonfiles))\n",
    "\n",
    "for j in jsonfiles:\n",
    "    with open(j) as f:\n",
    "        info = json.load(f)\n",
    "        print(get_map_types(info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypo 1: found 57 maps\n",
      "hypo 2: found 57 maps\n",
      "hypo 3: found 57 maps\n",
      "hypo 4: found 57 maps\n",
      "hypo 5: found 57 maps\n",
      "hypo 6: found 57 maps\n",
      "hypo 7: found 57 maps\n",
      "hypo 8: found 57 maps\n",
      "hypo 9: found 57 maps\n"
     ]
    }
   ],
   "source": [
    "unthresh_hmaps={}\n",
    "for hyp in range(1,10):\n",
    "    hmaps = glob.glob(os.path.join(output_dir,'resampled/*/hypo%d_unthresh.nii.gz'%hyp))\n",
    "    hmaps.sort()\n",
    "    unthresh_hmaps[hyp]=hmaps\n",
    "    print('hypo %d: found %d maps'%(hyp,len(hmaps)))\n",
    "    masker = nilearn.input_data.NiftiMasker(mask_img=full_mask_img)\n",
    "    concat_data = masker.fit_transform(hmaps)\n",
    "    concat_img = masker.inverse_transform(concat_data)\n",
    "    concat_img.to_filename(os.path.join(output_dir,'unthresh_concat/hypo%d.nii.gz'%hyp))\n",
    "    # compute range\n",
    "    concat_data=numpy.nan_to_num(concat_img.get_data())\n",
    "    datarange = numpy.max(concat_data,axis=3) - numpy.min(concat_data,axis=3)\n",
    "    range_img = nibabel.Nifti1Image(datarange,affine=concat_img.header.get_best_affine())\n",
    "    range_img.to_filename(os.path.join(output_dir,'unthresh_range/hypo%d.nii.gz'%hyp))\n",
    "    datavar = numpy.std(concat_data,axis=3)\n",
    "    var_img = nibabel.Nifti1Image(datavar,affine=concat_img.header.get_best_affine())\n",
    "    var_img.to_filename(os.path.join(output_dir,'unthresh_std/hypo%d.nii.gz'%hyp))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/poldrack/data_unsynced/NARPS/maps/resampled/ZFFBNRMO_51PW/hypo9_unthresh.nii.gz'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmaps[54]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

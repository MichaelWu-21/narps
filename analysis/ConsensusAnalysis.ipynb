{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consensus meta-analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/poldrack/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os,glob\n",
    "import numpy\n",
    "import nibabel\n",
    "import nilearn.plotting\n",
    "import nilearn.input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas \n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from utils import t_corr\n",
    "import scipy.stats\n",
    "%matplotlib inline\n",
    "\n",
    "orig_dir = '/Users/poldrack/data_unsynced/NARPS/maps/orig'\n",
    "output_dir = '/Users/poldrack/data_unsynced/NARPS/maps'\n",
    "template_img = os.path.join(output_dir,'templates/MNI152_T1_2mm.nii.gz')\n",
    "mask_img = os.path.join(output_dir,'templates/MNI152_T1_2mm_brain_mask.nii.gz')\n",
    "figure_dir = os.path.join(output_dir,'figures')\n",
    "results_dir = os.path.join(output_dir,'1sample_ttest')\n",
    "\n",
    "if not os.path.exists(results_dir):\n",
    "    os.mkdir(results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ttests for hypothesis 1\n",
      "running ttests for hypothesis 2\n",
      "running ttests for hypothesis 5\n",
      "running ttests for hypothesis 6\n",
      "running ttests for hypothesis 7\n",
      "running ttests for hypothesis 8\n",
      "running ttests for hypothesis 9\n"
     ]
    }
   ],
   "source": [
    "masker = nilearn.input_data.NiftiMasker(mask_img=mask_img)\n",
    "\n",
    "for hyp in [1,2,5,6,7,8,9]:\n",
    "    print('running ttests for hypothesis',hyp)\n",
    "    maps = glob.glob(os.path.join(output_dir,'zstat/*/hypo%d_unthresh.nii.gz'%hyp))\n",
    "    maps.sort()\n",
    "    data = masker.fit_transform(maps)\n",
    "    cc=numpy.corrcoef(data)\n",
    "    tvals = numpy.zeros(data.shape[1])\n",
    "    pvals = numpy.zeros(data.shape[1])\n",
    "    dfs = numpy.zeros(data.shape[1])\n",
    "    tvals,dfs,pvals=t_corr(data,cc)\n",
    "    #for i in range(data.shape[1]):\n",
    "    #    tvals[i],dfs[i],pvals[i]=t_corr(data[:,i],cc)\n",
    "    timg = masker.inverse_transform(tvals)\n",
    "    timg.to_filename(os.path.join(results_dir,'hypo%d_t.nii.gz'%hyp))\n",
    "    pimg = masker.inverse_transform(1-pvals)\n",
    "    pimg.to_filename(os.path.join(results_dir,'hypo%d_1-p.nii.gz'%hyp))\n",
    "    fdr_results = multipletests(pvals[0,:],0.05,'fdr_tsbh')\n",
    "    fdrimg = masker.inverse_transform(1 - fdr_results[1])\n",
    "    fdrimg.to_filename(os.path.join(results_dir,'hypo%d_1-fdr.nii.gz'%hyp))\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, ax = plt.subplots(7,1,figsize=(12,24))\n",
    "thresh=0.95\n",
    "hypnums=[1,2,5,6,7,8,9]\n",
    "cut_coords = [-24,-10,4,18,32,52,64]\n",
    "hypotheses= {1:'+gain: equal indiff',\n",
    "            2:'+gain: equal range',\n",
    "            3:'+gain: equal indiff',\n",
    "            4:'+gain: equal range',\n",
    "            5:'-loss: equal indiff',\n",
    "            6:'-loss: equal range',\n",
    "            7:'+loss: equal indiff',\n",
    "            8:'+loss: equal range',\n",
    "            9:'+loss:ER>EI'}\n",
    "\n",
    "for i,hyp in enumerate(hypnums):\n",
    "    pmap = os.path.join(output_dir,'unthresh_randomise/hypo%d_clustere_corrp_tstat1.nii.gz'%hyp)\n",
    "    tmap =  os.path.join(output_dir,'unthresh_randomise/hypo%d_tstat1.nii.gz'%hyp)\n",
    "    pimg = nibabel.load(pmap)\n",
    "    timg = nibabel.load(tmap)\n",
    "    threshdata = (pimg.get_data()>thresh)*timg.get_data()\n",
    "    threshimg = nibabel.Nifti1Image(threshdata,affine=timg.affine)\n",
    "    nilearn.plotting.plot_stat_map(threshimg, threshold=0.1, display_mode=\"z\", \n",
    "                colorbar=True,title='hyp %d:'%hyp+hypotheses[hyp],vmax=8,cmap='jet',\n",
    "                                  cut_coords = cut_coords,axes = ax[i])\n",
    "\n",
    "plt.savefig(os.path.join(figure_dir,'consensus_map.pdf'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run models with regressors for analysis features\n",
    "\n",
    "Include the following regressors:\n",
    "- was fmriprep used?\n",
    "- was motion regression used?\n",
    "- was confound regression (compcor or other) used?\n",
    "- was a separate RT regressor used?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create design files\n",
    "\n",
    "metadata_file = '/Users/poldrack/data_unsynced/NARPS/analysis_pipelines_SW.xlsx'\n",
    "metadata = pandas.read_excel(metadata_file,header=1)\n",
    "metadata['collectionID']=None\n",
    "for i in metadata.index:\n",
    "    metadata.loc[i,'collectionID']= '%s_%s'%(metadata.loc[i,'NV_collection_string'].strip(),metadata.loc[i,'teamID'].strip())\n",
    "metadata.index = metadata.collectionID\n",
    "metadata['used_fmriprep_data'] = (metadata['used_fmriprep_data']=='Yes').astype('int')*2 - 1\n",
    "metadata.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_use = ['used_fmriprep_data']\n",
    "md = metadata[columns_to_use]\n",
    "\n",
    "analysis_dir = os.path.join(output_dir,'unthresh_randomise_fmriprep')\n",
    "\n",
    "# just need to do it for one hypothesis since it's same for all\n",
    "hyp=1\n",
    "in_file=os.path.join(output_dir,'unthresh_concat/hypo%d.nii.gz'%hyp)\n",
    "label_file = os.path.join(output_dir,'unthresh_concat/labels_hypo%d.txt'%hyp)\n",
    "labels = pandas.read_csv(label_file,header=None)\n",
    "labels.columns = ['NV_collection_string']\n",
    "labels.index = labels.NV_collection_string\n",
    "labels['constant']=1\n",
    "nlabels=labels.shape[0]\n",
    "labels = labels.merge(md,left_index=True,right_index=True)\n",
    "assert labels.shape[0] == nlabels  # make sure we didn't lose any!\n",
    "del labels['NV_collection_string']\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write fsl design file\n",
    "designfile = os.path.join(analysis_dir,'design.txt')\n",
    "with open(designfile,'w') as f:\n",
    "    f.write('/NumWaves %d\\n'%labels.shape[1])\n",
    "    f.write('/NumPoints %d\\n/Matrix\\n'%labels.shape[0])\n",
    "    f.write(labels.to_string(header=False,index=False))\n",
    "\n",
    "confile = os.path.join(analysis_dir,'design.con')\n",
    "with open(confile,'w') as f:\n",
    "    f.write('/NumWaves 2\\n')\n",
    "    f.write('/NumPoints 4\\n/Matrix\\n')\n",
    "    f.write('1\\t0\\n')\n",
    "    f.write('-1\\t0\\n')\n",
    "    f.write('0\\t1\\n')\n",
    "    f.write('0\\t-1\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hyp in [5]:\n",
    "    rand = fsl.Randomise(in_file=os.path.join(output_dir,'unthresh_concat/hypo%d.nii.gz'%hyp), \n",
    "                         mask = mask_img,\n",
    "                        base_name=os.path.join(output_dir,'unthresh_randomise_fmriprep/hypo%d'%hyp),\n",
    "                        num_perm=2500,c_thresh=3,\n",
    "                        var_smooth=True,design_mat=designfile,\n",
    "                        tcon=confile)\n",
    "    print(rand.cmdline)\n",
    "    rand.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cope_desc = {1:'pos',2:'neg',3:''}\n",
    "for cope in range(1,5):\n",
    "    for i,hyp in enumerate(hypnums):\n",
    "        pmap = os.path.join(output_dir,'unthresh_randomise_fmriprep/hypo%d_clustere_corrp_tstat%d.nii.gz'%(hyp,cope))\n",
    "        tmap =  os.path.join(output_dir,'unthresh_randomise_fmriprep/hypo%d_tstat%d.nii.gz'%(hyp,cope))\n",
    "        pimg = nibabel.load(pmap)\n",
    "        timg = nibabel.load(tmap)\n",
    "        threshdata = (pimg.get_data()>thresh)*timg.get_data()\n",
    "        threshimg = nibabel.Nifti1Image(threshdata,affine=timg.affine)\n",
    "        nilearn.plotting.plot_stat_map(threshimg, threshold=0.1, display_mode=\"z\", \n",
    "                    colorbar=True,title='hyp %d:'%hyp+hypotheses[hyp],vmax=8,cmap='jet',\n",
    "                                      cut_coords = cut_coords,axes = ax[i])\n",
    "\n",
    "    plt.savefig(os.path.join(figure_dir,'consensus_map_cope%d.pdf'%cope))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

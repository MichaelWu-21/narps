### Code for NARPS data analysis

[![DOI](https://zenodo.org/badge/85984198.svg)](https://zenodo.org/badge/latestdoi/85984198)

[![CircleCI](https://circleci.com/gh/poldrack/narps.svg?style=svg)](https://circleci.com/gh/poldrack/narps)

[![Codacy Badge](https://api.codacy.com/project/badge/Grade/c35f17b180aa4b1e8cbd33b9b1473c3e)](https://www.codacy.com/app/poldrack/narps?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=poldrack/narps&amp;utm_campaign=Badge_Grade)

[![Coverage Status](https://coveralls.io/repos/github/poldrack/narps/badge.svg?branch=master)](https://coveralls.io/github/poldrack/narps?branch=master)

#### Setup

In order to run this code, you must obtain the URL for the original data from Russ Poldrack - these data will be made publicly available upon publication of the paper.

Once you have the URL, you can specify it in either of two ways:

-    create an environment variable called "DATA_URL"
-    create a json file in the analysis directory called "info.json" and include a variable called "DATA_URL"

The required data (all contained in the unzipped ```orig``` directory) are:

-   thresholded and unthresholded images for each team/hypothesis (teams excluded from the main analysis are included in the ```rejected``` directory)

-   Metadata files:
    -   ```analysis_pipelines_SW.xlsx``` (information about analysis pipelines)
    -   ```narps_neurovault_images_details.csv``` (information about images)
    -]  ```narps_results.xlsx``` (information about team decisions)

In addition, there is a set of template files (redistributed from the FSL distribution) contained in the ```templates``` directory:
    -   ```templates/MNI152_T1_2mm.nii.gz```
    -   ```templates/MNI152_T1_2mm_brain_mask.nii.gz```

#### Dockerized analysis pipeline

To run the full analysis pipeline using Docker, do the following:

-   Install the [Docker client](https://docs.docker.com/install/)
-   set the following environment variables:
    -   ```NARPS_BASEDIR```: directory containing the original NARPS data files (which need not be the directory where the code is located)
-   clone this repository and cd to the cloned directory
-   use the following command to run the full pipeline: ```make run-all```

This performs the following steps:

-   Preparation of the data for analysis(using narps.py)
-   Preparation of the metadata (using PrepareMetadata.py)
-   Analysis of the maps (using AnalyzeMaps.py)
-   Analysis of the decisions (using AnalyzeDecisions.Rmd)
-   Consensus analysis across teams (using ConsensusAnalysis.py)

The outputs can be found in the subdirectories of NARPS_BASEDIR:
-   ```maps``` - all of the intermediate maps generated by preprocessing
-   ```figures``` - figures generated by the analysis code
-   ```metadata``` - additional metadata files generated by the preparation code
-   ```cached``` - the cached narps structure 

This will use the existing version of the docker image from Dockerhub.  If you wish to build the Docker image locally, you should change the DOCKER_USERNAME variable in the Makefile to your own username, and then run ```make docker-build```.

### Local execution

Execution via Docker is recommended, but the analysis can also be run locally, using ```make run-all-local``` - this will require that you have all of the various requirements in place.  Right now these must be inferred from the Dockerfile, but ```make install-R-packages``` will install all of the necessary R packages locally.



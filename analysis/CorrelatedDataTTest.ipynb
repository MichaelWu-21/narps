{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Consensus analysis using mean Z score\n",
    "import numpy\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from Tom:\n",
    "\n",
    "Following on our chat, I realise that my notes were missing some indices. Here’s a corrected version:\n",
    "\n",
    "    Y_i: N-vector of T scores (or whatever) at voxel i\n",
    "    Var(Y_i) =  Sigma_i\n",
    "\n",
    "where Sigma_i is the NxN covariance matrix. But to be practical, we need to assume *common* variance, and a *global* correlation:\n",
    "\n",
    "    Var(Y_i) =  sigma^2 Q\n",
    "\n",
    "Where sigma is the (scalar) variance for whole image, Q the common NxN correlation (*not* covariance)\n",
    "\n",
    "Then the average is \n",
    "\n",
    "    bar{Y_i} = X’ Y_i / N\n",
    "\n",
    "where X is a column of ones and\n",
    "\n",
    "    Var(bar{Y_i}) =  sigma^2   X’ Q X / N^2\n",
    "\n",
    "So then the T test is \n",
    "\n",
    "    T_i = bar(Y_i) / sqrt(Var(bar{Y_i}))\n",
    "\n",
    "I don't think the variance should be estimated over submissions/teams, but if you were to do so you could do it at each voxel as:\n",
    "\n",
    "    Y_i’ R Y_i / tr(RQ)\n",
    "\n",
    "then the effective DF is as you say,\n",
    "\n",
    "    v = tr(RQ)^2 / tr(RQRQ)\n",
    "\n",
    "But you could also use the naive estimate\n",
    "\n",
    "    hat{sigma^2_i} = Y_i’ R Y_i / (N-1)\n",
    "    \n",
    "Finally, this will give a completely noramlised test statistic... i.e. a T_i image that is variance 1.  If we wish to retain the average variance of the various test statistics, we simply need to drop sigma^2 from the definition of Var(bar{Y_i})."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_corr(y,res_mean=None,res_var=None,Q=None):\n",
    "    \"\"\"\n",
    "    perform a one-sample t-test on correlated data\n",
    "    y = data (n observations X n vars)\n",
    "    Q = \"known\" correlation across observations (use empirical correlation based on maps)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Jeanette:\n",
    "    # This paper calculates the df for an F-test, so the chisquare bit we need is in there.  Your t-statistic will come from\n",
    "    # X = column of 1's (design matrix)\n",
    "\n",
    "    if len(y.shape)==1:\n",
    "        y = y[:,numpy.newaxis]\n",
    "    assert y.shape[1]==1\n",
    "    \n",
    "    npts = y.shape[0]\n",
    "    X = numpy.ones((npts,1))\n",
    "\n",
    "    if res_mean is None:\n",
    "        res_mean = 0\n",
    "\n",
    "    if res_var is None:\n",
    "        res_var = 1\n",
    "  \n",
    "    if Q is None:\n",
    "        Q = numpy.eye(npts)\n",
    "\n",
    "    # R = I{n} - X(X'X)^{-1}X'\n",
    "    R = numpy.eye(npts) - X.dot(numpy.linalg.inv(X.T.dot(X))).dot(X.T)\n",
    "\n",
    "    \n",
    "    VarMean = res_var * X.T.dot(Q).dot(X) / npts**2\n",
    "\n",
    "    # T  =  mean(y,0)/s-hat-2\n",
    "    # use diag to get s_hat2 for each variable \n",
    "    T = (numpy.mean(y,0)-res_mean)/numpy.sqrt(VarMean)*numpy.sqrt(res_var) + res_mean\n",
    "\n",
    "    # degrees of freedom = v = tr(RQ)^2/tr(RQRQ)\n",
    "    df = (numpy.trace(R.dot(Q))**2)/numpy.trace(R.dot(Q).dot(R).dot(Q))\n",
    "    p = 1 - scipy.stats.t.cdf(T,df=df)\n",
    "    return(T,df,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0429"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npts = 36\n",
    "nvars = 10\n",
    "nruns=1000\n",
    "alpha=.05\n",
    "mu=0\n",
    "# simulate independent case\n",
    "pvals= numpy.zeros((nruns,nvars))\n",
    "\n",
    "for i in range(nruns):\n",
    "    y = numpy.random.randn(npts,nvars)\n",
    "    result = t_corr(y)\n",
    "    pvals.append(result[2].tolist())\n",
    "pvals_mtx = numpy.array(pvals)   \n",
    "numpy.mean(pvals_mtx<=0.05)   # If p-values valid/nominal, 5% should be below 0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "npts = 36\n",
    "nvars = 10\n",
    "nruns=100\n",
    "rho=0.9\n",
    "\n",
    "# now simulate correlated data\n",
    "\n",
    "def mk_CS_Cov(npts,rho):\n",
    "    Cov = (1-rho)*numpy.identity(npts)+rho*numpy.ones([npts,npts])\n",
    "    return(Cov)\n",
    "            \n",
    "Q = mk_CS_Cov(npts,rho)\n",
    "\n",
    "def mk_correlated_data(npts,nvars,Cov):\n",
    "    \n",
    "    pvals = []\n",
    "    for i in range(nruns):\n",
    "        y = numpy.random.multivariate_normal(numpy.zeros(npts),Cov,nvars).T\n",
    "    return(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.048"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply simulation 'right' way, telling t_corr about correlation\n",
    "pvals = []\n",
    "for i in range(nruns):\n",
    "    y = mk_correlated_data(npts,nvars,Q)\n",
    "    result = t_corr(y,0,1,Q)\n",
    "    pvals.append(result[2].tolist())\n",
    "pvals_mtx = numpy.array(pvals)   \n",
    "numpy.mean(pvals_mtx<=0.05)   # If p-values valid/nominal, 5% should be below 0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.412"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply simulation 'wrong' way, telling t_corr about correlation\n",
    "pvals = []\n",
    "for i in range(nruns):\n",
    "    y = mk_correlated_data(npts,nvars,Q)\n",
    "    result = t_corr(y)\n",
    "    pvals.append(result[2].tolist())\n",
    "pvals_mtx = numpy.array(pvals)   \n",
    "numpy.mean(pvals_mtx<=0.05)   # If p-values valid/nominal... but you'll surely find it higher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.987010776746394 1.4961018870404887\n"
     ]
    }
   ],
   "source": [
    "# Now try a *non* null simulation\n",
    "Mn=2\n",
    "Sd=1.5\n",
    "Tvals = []\n",
    "for i in range(nruns):\n",
    "    y = Mn+Sd*mk_correlated_data(npts,nvars,Q)\n",
    "    result = t_corr(y,2,1.5,Q)\n",
    "    Tvals.append(result[0].tolist())\n",
    "Tvals_mtx = numpy.array(Tvals)\n",
    "print(numpy.mean(Tvals_mtx),numpy.std(Tvals_mtx))   # Should match Mn & Sd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

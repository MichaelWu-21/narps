{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Consensus analysis using mean Z score\n",
    "import numpy\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from Tom:\n",
    "\n",
    "Following on our chat, I realise that my notes were missing some indices. Here’s a corrected version:\n",
    "\n",
    "    Y_i: N-vector of T scores (or whatever) at voxel i\n",
    "    Var(Y_i) =  Sigma_i\n",
    "\n",
    "where Sigma_i is the NxN covariance matrix. But to be practical, we need to assume *common* variance, and a *global* correlation:\n",
    "\n",
    "    Var(Y_i) =  sigma^2 Q\n",
    "\n",
    "Where sigma is the (scalar) variance for whole image, Q the common NxN correlation (*not* covariance)\n",
    "\n",
    "Then the average is \n",
    "\n",
    "    bar{Y_i} = X’ Y_i / N\n",
    "\n",
    "where X is a column of ones and\n",
    "\n",
    "    Var(bar{Y_i}) =  sigma^2   X’ Q X / N^2\n",
    "\n",
    "So then the T test is \n",
    "\n",
    "    T_i = bar(Y_i) / sqrt(Var(bar{Y_i}))\n",
    "\n",
    "I don't think the variance should be estimated over submissions/teams, but if you were to do so you could do it at each voxel as:\n",
    "\n",
    "    Y_i’ R Y_i / tr(RQ)\n",
    "\n",
    "then the effective DF is as you say,\n",
    "\n",
    "    v = tr(RQ)^2 / tr(RQRQ)\n",
    "\n",
    "But you could also use the naive estimate\n",
    "\n",
    "    hat{sigma^2_i} = Y_i’ R Y_i / (N-1)\n",
    "    \n",
    "Finally, this will give a completely noramlised test statistic... i.e. a T_i image that is variance 1.  If we wish to retain the average variance of the various test statistics, we simply need to drop sigma^2 from the definition of Var(bar{Y_i})."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def t_corr(y,s_hat_2=None,Q=None):\n",
    "    \"\"\"\n",
    "    perform a one-sample t-test on correlated data\n",
    "    y = data (n observations X n vars)\n",
    "    Q = \"known\" correlation across observations (use empirical correlation based on maps)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Jeanette:\n",
    "    # This paper calculates the df for an F-test, so the chisquare bit we need is in there.  Your t-statistic will come from\n",
    "    # X = column of 1's (design matrix)\n",
    "\n",
    "    X = numpy.ones((npts,1))\n",
    "\n",
    "    if Q is None:\n",
    "        #print('no Q specified, using identity (uncorrelated)')\n",
    "        Q = numpy.eye(npts)\n",
    "\n",
    "    # R = I{n} - X(X'X)^{-1}X'\n",
    "    R = numpy.eye(npts) - X.dot(numpy.linalg.inv(X.T.dot(X))).dot(X.T)\n",
    "\n",
    "    if s_hat_2 is None:\n",
    "        s_hat_2 = 1\n",
    "        # Don't think this is needed/correct:\n",
    "        # # s-hat-2 = y'Ry/tr(RQ)\n",
    "        # s_hat_2 = y.T.dot(R).dot(y)/(numpy.trace(R.dot(Q)))\n",
    "        \n",
    "    VarMean = s_hat_2 * X.T.dot(Q).dot(X) / npts**2\n",
    "\n",
    "    # T  =  mean(y,0)/s-hat-2\n",
    "    # use diag to get s_hat2 for each variable \n",
    "    T = numpy.mean(y,0)/numpy.sqrt(VarMean)\n",
    "\n",
    "    # degrees of freedom = v = tr(RQ)^2/tr(RQRQ)\n",
    "    df = (numpy.trace(R.dot(Q))**2)/numpy.trace(R.dot(Q).dot(R).dot(Q))\n",
    "    p = scipy.stats.t.cdf(T,df=df)\n",
    "    return(T,df,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "npts = 36\n",
    "nvars = 10\n",
    "nruns=1000\n",
    "\n",
    "# simulate independent case\n",
    "pvals = []\n",
    "for i in range(nruns):\n",
    "    y = numpy.random.randn(npts,nvars)\n",
    "    result = t_corr(y)\n",
    "    pvals.append(result[2].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class:  ndarray\n",
      "shape:  (36, 10)\n",
      "strides:  (8, 288)\n",
      "itemsize:  8\n",
      "aligned:  True\n",
      "contiguous:  False\n",
      "fortran:  True\n",
      "data pointer: 0x7fcbbf1b5800\n",
      "byteorder:  little\n",
      "byteswap:  False\n",
      "type: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-5.50695625,  2.394767  ,  1.34272241,  4.28641553,  5.18283019,\n",
       "          1.8052387 ,  3.61308617,  1.88095123, -0.82104834, -7.2929705 ]]),\n",
       " 35.000000000000036,\n",
       " array([[1.72526607e-06, 9.88940803e-01, 9.05997126e-01, 9.99932357e-01,\n",
       "         9.99995386e-01, 9.60177026e-01, 9.99529786e-01, 9.65840455e-01,\n",
       "         2.08588141e-01, 8.03014600e-09]]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Work in progress!  pvals_mtx = numpy.array(pvals)\n",
    "### Simulate dependent case\n",
    "numpy.mean(pvals_mtx<=0.05)   # If p-values valid/nominal, 5% should be below 0.05\n",
    "npts = 36\n",
    "nvars = 10\n",
    "nruns=1000\n",
    "rho=0.9\n",
    "Cov = (1-rho)*numpy.identity(npts)+rho*numpy.ones([npts,npts])\n",
    "y = numpy.random.multivariate_normal(numpy.zeros(npts),Cov,nvars).T\n",
    "numpy.info(y)\n",
    "result = t_corr(y)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "npts = 36\n",
    "nvars = 10\n",
    "nruns=1000\n",
    "rho=0.9\n",
    "# now simulate correlated data\n",
    "\n",
    "def mk_correlated_data(npts,nvars,r,rho):\n",
    "    Cov = (1-rho)*numpy.identity(npts)+rho*numpy.ones(npts,npts)\n",
    "    \n",
    "    pvals = []\n",
    "    for i in range(nruns):\n",
    "        y = numpy.random.multivariate_normal(numpy.zeros(npts),Cov,nvars).T\n",
    "        result = t_corr(y)\n",
    "        pvals.append(result[2].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "# Tom:\n",
    "# Yup... that’s the direction, but need to work out the variance of the mean too, not just worry about DF:\n",
    "\n",
    "# So...\n",
    "\n",
    "#     Y_i: N-vector of T scores (or whatever) at voxel i\n",
    "#     Var(Y_i) =  Sigma_i\n",
    "\n",
    "# where Sigma_i is the NxN covariance matrix. But to be practical, we need to assume common variance, and a global correlation:\n",
    "\n",
    "#     Var(Y_i) =  sigma_i Q\n",
    "\n",
    "# Where sigma_i is the (scalar) variance at voxel i, Q the common correlation\n",
    "\n",
    "# Then the average is \n",
    "#     bar{Y_i} = X’Y_i/N\n",
    "# and\n",
    "#     Var(bar{Y}) =  sigma^2_i X_i’ Q X_i / N^2\n",
    "\n",
    "# So then the T test is \n",
    "#    T = bar(Y) / sqrt(Var(bar{Y}))\n",
    "\n",
    "# If you estimate the variance as you suggest\n",
    "\n",
    "#    hat{sigma^2_i} = Y’RY / tr(RQ)\n",
    "\n",
    "# then the effective DF is as you say,\n",
    "\n",
    "#     v = tr(RQ)^2 / tr(RQRQ)\n",
    "\n",
    "# But you could also use the naive estimate\n",
    "\n",
    "#    hat{sigma^2_i} = Y’RY / (N-1)\n",
    "\n",
    "# but then the DF are\n",
    "\n",
    "#    v = (N-1)^2 / tr(RQRQ)\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

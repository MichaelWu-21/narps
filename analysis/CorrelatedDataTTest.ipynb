{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Consensus analysis using mean Z score\n",
    "import numpy\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from Tom:\n",
    "\n",
    "Following on our chat, I realise that my notes were missing some indices. Here’s a corrected version:\n",
    "\n",
    "    Y_i: N-vector of T scores (or whatever) at voxel i\n",
    "    Var(Y_i) =  Sigma_i\n",
    "\n",
    "where Sigma_i is the NxN covariance matrix. But to be practical, we need to assume *common* variance, and a *global* correlation:\n",
    "\n",
    "    Var(Y_i) =  sigma^2 Q\n",
    "\n",
    "Where sigma is the (scalar) variance for whole image, Q the common NxN correlation (*not* covariance)\n",
    "\n",
    "Then the average is \n",
    "\n",
    "    bar{Y_i} = X’ Y_i / N\n",
    "\n",
    "where X is a column of ones and\n",
    "\n",
    "    Var(bar{Y_i}) =  sigma^2   X’ Q X / N^2\n",
    "\n",
    "So then the T test is \n",
    "\n",
    "    T_i = bar(Y_i) / sqrt(Var(bar{Y_i}))\n",
    "\n",
    "I don't think the variance should be estimated over submissions/teams, but if you were to do so you could do it at each voxel as:\n",
    "\n",
    "    Y_i’ R Y_i / tr(RQ)\n",
    "\n",
    "then the effective DF is as you say,\n",
    "\n",
    "    v = tr(RQ)^2 / tr(RQRQ)\n",
    "\n",
    "But you could also use the naive estimate\n",
    "\n",
    "    hat{sigma^2_i} = Y_i’ R Y_i / (N-1)\n",
    "    \n",
    "Finally, this will give a completely noramlised test statistic... i.e. a T_i image that is variance 1.  If we wish to retain the average variance of the various test statistics, we simply need to drop sigma^2 from the definition of Var(bar{Y_i})."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_corr(y,s_hat_2=None,Q=None):\n",
    "    \"\"\"\n",
    "    perform a one-sample t-test on correlated data\n",
    "    y = data (n observations X n vars)\n",
    "    Q = \"known\" correlation across observations (use empirical correlation based on maps)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Jeanette:\n",
    "    # This paper calculates the df for an F-test, so the chisquare bit we need is in there.  Your t-statistic will come from\n",
    "    # X = column of 1's (design matrix)\n",
    "\n",
    "    X = numpy.ones((npts,1))\n",
    "\n",
    "    if Q is None:\n",
    "        #print('no Q specified, using identity (uncorrelated)')\n",
    "        Q = numpy.eye(npts)\n",
    "\n",
    "    # R = I{n} - X(X'X)^{-1}X'\n",
    "    R = numpy.eye(npts) - X.dot(numpy.linalg.inv(X.T.dot(X))).dot(X.T)\n",
    "\n",
    "    if s_hat_2 is None:\n",
    "        s_hat_2 = 1\n",
    "        # Don't think this is needed/correct:\n",
    "        # # s-hat-2 = y'Ry/tr(RQ)\n",
    "        # s_hat_2 = y.T.dot(R).dot(y)/(numpy.trace(R.dot(Q)))\n",
    "        \n",
    "    VarMean = s_hat_2 * X.T.dot(Q).dot(X) / npts**2\n",
    "\n",
    "    # T  =  mean(y,0)/s-hat-2\n",
    "    # use diag to get s_hat2 for each variable \n",
    "    T = numpy.mean(y,0)/numpy.sqrt(VarMean)\n",
    "\n",
    "    # degrees of freedom = v = tr(RQ)^2/tr(RQRQ)\n",
    "    df = (numpy.trace(R.dot(Q))**2)/numpy.trace(R.dot(Q).dot(R).dot(Q))\n",
    "    p = scipy.stats.t.cdf(T,df=df)\n",
    "    return(T,df,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0463"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npts = 36\n",
    "nvars = 10\n",
    "nruns=1000\n",
    "\n",
    "# simulate independent case\n",
    "pvals = []\n",
    "for i in range(nruns):\n",
    "    y = numpy.random.randn(npts,nvars)\n",
    "    result = t_corr(y)\n",
    "    pvals.append(result[2].tolist())\n",
    "pvals_mtx = numpy.array(pvals)   \n",
    "numpy.mean(pvals_mtx<=0.05)   # If p-values valid/nominal, 5% should be below 0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "npts = 36\n",
    "nvars = 10\n",
    "nruns=100\n",
    "rho=0.9\n",
    "\n",
    "# now simulate correlated data\n",
    "\n",
    "def mk_CS_Cov(npts,rho):\n",
    "    Cov = (1-rho)*numpy.identity(npts)+rho*numpy.ones([npts,npts])\n",
    "    return(Cov)\n",
    "            \n",
    "Q = mk_CS_Cov(npts,rho)\n",
    "\n",
    "def mk_correlated_data(npts,nvars,Cov):\n",
    "    \n",
    "    pvals = []\n",
    "    for i in range(nruns):\n",
    "        y = numpy.random.multivariate_normal(numpy.zeros(npts),Cov,nvars).T\n",
    "    return(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.051"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply simulation 'right' way, telling t_corr about correlation\n",
    "pvals = []\n",
    "for i in range(nruns):\n",
    "    y = mk_correlated_data(npts,nvars,Q)\n",
    "    result = t_corr(y,None,Q)\n",
    "    pvals.append(result[2].tolist())\n",
    "pvals_mtx = numpy.array(pvals)   \n",
    "numpy.mean(pvals_mtx<=0.05)   # If p-values valid/nominal, 5% should be below 0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.374"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply simulation 'wrong' way, telling t_corr about correlation\n",
    "pvals = []\n",
    "for i in range(nruns):\n",
    "    y = mk_correlated_data(npts,nvars,Q)\n",
    "    result = t_corr(y)\n",
    "    pvals.append(result[2].tolist())\n",
    "pvals_mtx = numpy.array(pvals)   \n",
    "numpy.mean(pvals_mtx<=0.05)   # If p-values valid/nominal... but you'll surely find it higher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n",
      "[1.16832173 1.2655247  0.91872055 0.96695345 0.75922581 0.38582622\n",
      " 0.53303207 1.75454439 1.2296246  1.20750502 0.47400494 0.8325709\n",
      " 1.02920045 1.17808991 0.86505562 1.24630867 0.64809131 1.40406542\n",
      " 1.28193027 0.60977046 1.00211555 0.3033739  1.51665266 0.39704934\n",
      " 0.61669889 1.18616785 1.01061705 1.1419307  1.30373429 0.84820372\n",
      " 1.33873225 0.73156287 0.97850548 1.31734443 0.97902405 1.48909115]\n",
      "[[ 5.98652845  1.84670152 -5.54931802 -6.9470364  -7.26680022 -0.2415651\n",
      "  -0.8004416  -2.97792895 -0.67411505 -5.94823149]]\n",
      "35.000000000000036\n"
     ]
    }
   ],
   "source": [
    "print(rho)\n",
    "print(y[:,0])\n",
    "print(result[0])\n",
    "print(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.74765142509552"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally do a simulation where variance is wacky... output should also be wacky\n",
    "BigSd=3\n",
    "Tvals = []\n",
    "pvals = []\n",
    "for i in range(nruns):\n",
    "    y = BigSd*mk_correlated_data(npts,nvars,Q)\n",
    "    result = t_corr(y)\n",
    "    pvals.append(result[2].tolist())\n",
    "    Tvals.append(result[0].tolist())\n",
    "pvals_mtx = numpy.array(pvals)   \n",
    "Tvals_mtx = numpy.array(Tvals)   \n",
    "numpy.std(Tvals_mtx)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.05869892 -1.22075625 -0.32704517 -0.28239941 -0.89451499 -1.09842964\n",
      " -1.25614818 -0.6639502  -0.8224491  -1.19889906 -0.60441808 -1.30108216\n",
      " -0.96012083 -1.02403721 -0.71249447 -1.21743339 -0.60207883 -0.99584428\n",
      " -0.9882371  -0.84661183 -0.64463676 -0.38856144 -0.32685999 -0.69046695\n",
      " -0.83947943 -0.76223982 -1.25047426 -0.80118529 -1.23095401 -0.84807762\n",
      " -0.94671084 -0.99286439 -0.78922693 -1.08084965 -0.95542829 -0.77292297]\n",
      "35.000000000000036\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.141288117924207 13.917895803567212 12.179686958090187\n"
     ]
    }
   ],
   "source": [
    "# simulate independent case\n",
    "pvals = []\n",
    "Tvals = []\n",
    "for i in range(nruns):\n",
    "    y = 4*mk_correlated_data(npts,nvars,mk_CS_Cov(npts,0.3))\n",
    "    result = t_corr(y)\n",
    "    pvals.append(result[2].tolist())\n",
    "    Tvals.append(result[0].tolist())\n",
    "pvals_mtx = numpy.array(pvals)   \n",
    "numpy.mean(pvals_mtx<=0.05)   # If p-values valid/nominal, 5% should be below 0.05\n",
    "Tvals_mtx = numpy.array(Tvals)   \n",
    "print(numpy.std(Tvals_mtx), numpy.std(Tvals_mtx[:,0,0]),numpy.std(Tvals_mtx[0,0,:])  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 0.3, 0.3, ..., 0.3, 0.3, 0.3],\n",
       "       [0.3, 1. , 0.3, ..., 0.3, 0.3, 0.3],\n",
       "       [0.3, 0.3, 1. , ..., 0.3, 0.3, 0.3],\n",
       "       ...,\n",
       "       [0.3, 0.3, 0.3, ..., 1. , 0.3, 0.3],\n",
       "       [0.3, 0.3, 0.3, ..., 0.3, 1. , 0.3],\n",
       "       [0.3, 0.3, 0.3, ..., 0.3, 0.3, 1. ]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mk_CS_Cov(npts,0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

---
title: "Decision analysis"
output:
  html_document:
    df_print: paged
---

Analyze decisions across teams.

```{r setup, echo=FALSE,message=FALSE}

use_checkpoint = TRUE

s = Sys.info()
if (s['sysname'] == 'Darwin'){
  use_checkpoint = FALSE
}

if (use_checkpoint) {
  library(checkpoint)
  checkpointDir <- tempfile(pattern = "checkpoint")
  dir.create(checkpointDir)
  dir.create(file.path(checkpointDir, ".checkpoint"))
  checkpoint("2019-08-13", checkpointLocation = checkpointDir)
}

library(plyr)
library(tidyverse)
library(lmerTest)
library(lme4)
library(emmeans) 
library(pscl)
library(arm)
library(MuMIn)
library(multcomp)
library(multcompView)
library(optimx)
library(xtable)
library(psych)
library(knitr)

basedir = Sys.getenv('NARPS_BASEDIR')
if (basedir == ""){
   # use default
   basedir = "/data"
}

```

## Data setup 

Load the data and clean up some variables.  Requires metadata that is created by PrepareMetadata.ipynb

```{r loadData}
# load and clean up data
cat(sprintf('using basedir: %s', basedir))

narps_df <- read_csv(paste(basedir,
                           'metadata/all_metadata.csv',
                           sep='/'))

narps_df <- narps_df %>% 
  mutate(Confidence = as.ordered(narps_df$Confidence))


narps_df$testing[is.na(narps_df$testing)] <- "Other"
narps_df$teamID = as.factor(narps_df$teamID)
narps_df$varnum = as.factor(narps_df$varnum)
```

Estimate correlation between reported smoothing kernel and estimated image smoothness.

```{r smoothCorr}
cor(narps_df$fwhm,narps_df$smoothing_coef,
    use='pairwise.complete',
    method='spearman')
```

## Make decision summary table

Compute data for Table 1 in paper

```{r}
desc <- c('Positive parametric effect of gains in the vmPFC (equal indifference group)',
'Positive parametric effect of gains in the vmPFC (equal range group)',
'Positive parametric effect of gains in the ventral striatum (equal indifference group)',
'Positive parametric effect of gains in the ventral striatum (equal range group)',
'Negative parametric effect of losses in the vmPFC (equal indifference group)',
'Negative parametric effect of losses in the vmPFC (equal range group)',
'Positive parametric effect of losses in the amygdala (equal indifference group)',
'Positive parametric effect of losses in the amygdala (equal range group)',
'Greater positive response to losses in amygdala for equal range group vs. equal indifference group')

decision_df <- narps_df %>%
  dplyr::select(Decision, varnum, Similar, Confidence) 

decision_summary <- decision_df %>%
  group_by(varnum) %>%
  summarise(pDecision = mean(Decision), 
            medianSimilar = median(Similar),
            madSimilar = mad(Similar, constant=1),
            medianConfidence = median(as.numeric(Confidence)),
            madConfidence = mad(as.numeric(Confidence), constant=1))
decision_summary$Description <- desc
decision_summary <- decision_summary[c('varnum',
                                       'Description',
                                       'pDecision',
                                       'medianSimilar',
                                       'madSimilar',
                                       'medianConfidence',
                                       'madConfidence')]
write.table(decision_summary,
            file=paste(basedir,"figures/Table1.txt",sep='/'))

decision_summary

```

## Check independent variables

Note that the correlations are not interpretable for the factorial variables - the plot is shown simply to provide some insight into the relationships between the different variables and their distributions.

```{r vis_model}

df_for_vis <- narps_df %>% 
  drop_na(fwhm,used_fmriprep_data,package,testing) %>%
  dplyr::select(c(fwhm,used_fmriprep_data,package,testing,smoothing_coef, movement_modeling))

pairs.panels(df_for_vis)

```

## Models

First run mixed model across full dataset to assess overall effects on hypothesis acceptance. We use nlminb as the optimizer because the model failed to converge using the standard optimizer in lmer.

```{r fullModel}
hyp_df = narps_df %>% drop_na(fwhm,
                              used_fmriprep_data,
                              package,
                              testing)
hyp_df <- hyp_df %>%  mutate(
    package = factor(package, c('SPM', 'FSL', 'AFNI', 'Other')),
    testing = factor(testing),
    used_fmriprep_data = factor(used_fmriprep_data)) %>%
  mutate(testing = recode_factor(hyp_df$testing, ARI = 'Other'))

m_hyp_full = glmer(Decision ~ varnum + fwhm + used_fmriprep_data + package + testing + movement_modeling + (1|teamID),
            data = hyp_df,family=binomial,
            control = glmerControl(optimizer ='optimx', 
                                   optCtrl=list(method='nlminb')))

summary_full_model <- summary(m_hyp_full)
print(summary_full_model)

r.squaredGLMM(m_hyp_full)

```

Get odds ratios for factorial variables.

```{r}
# from https://stackoverflow.com/questions/26417005/odds-ratio-and-confidence-intervals-from-glmer-output
odds_ratios <- exp(fixef(m_hyp_full))
# this uses the immensely faster but less accurate Wald method for confidence intervals
cc <- confint(m_hyp_full,parm="beta_",method="Wald")  
ctab <- cbind(est=odds_ratios,exp(cc))
kable(ctab)
write.table(ctab,
            file=paste(basedir,"figures/OddsRatios.txt",sep='/'))

```


### Model comparisons

Estimate a set of models leaving out each variable of interest, so that we can then use model comparison to estimate the effect sizes.  This is particularly necessary for the factor variables since they are not represented by a single variable in the model.

#### Model without hypothesis

```{r hypModel}
m_hyp_nohyp = glmer(Decision ~ fwhm + used_fmriprep_data + package + testing + movement_modeling + (1|teamID),
            data = hyp_df,family=binomial,
            control = glmerControl(optimizer ='optimx', 
                                   optCtrl=list(method='nlminb')))

anova_hyp<- anova(m_hyp_full,
                  m_hyp_nohyp,
                  test='Chisq')
print(anova_hyp)

# compute delta r-squared between this model and full model
delta_r2_hyp <- r.squaredGLMM(m_hyp_full) - r.squaredGLMM(m_hyp_nohyp) 
print(delta_r2_hyp)
```

#### Model without smoothing

```{r nosmoothModel}
m_hyp_nosmooth = glmer(Decision ~ varnum + used_fmriprep_data + package + testing + movement_modeling + (1|teamID),
            data = hyp_df,family=binomial,
            control = glmerControl(optimizer ='optimx', 
                                   optCtrl=list(method='nlminb')))

anova_smoothing <- anova(m_hyp_full,
                         m_hyp_nosmooth,
                         test='Chisq')
print(anova_smoothing)

emtrends(m_hyp_full,specs='fwhm',var='fwhm')

# compute delta r-squared between this model and full model
delta_r2_smoothing <- r.squaredGLMM(m_hyp_full) - r.squaredGLMM(m_hyp_nosmooth) 
print(delta_r2_smoothing)
```

#### Model without fmriprep

```{r noprepModel}
m_hyp_noprep = glmer(Decision ~ varnum + fwhm + package + testing + movement_modeling + (1|teamID),
            data = hyp_df,family=binomial,
            control = glmerControl(optimizer ='optimx', 
                                   optCtrl=list(method='nlminb')))
anova_fmriprep <- anova(m_hyp_full,
                        m_hyp_noprep,
                        test='Chisq')
print(anova_fmriprep)

emmeans(m_hyp_full,'used_fmriprep_data')

# compute delta r-squared between this model and full model
delta_r2_fmriprep <- r.squaredGLMM(m_hyp_full) - r.squaredGLMM(m_hyp_noprep) 

print(delta_r2_fmriprep)
```

#### Model without software package

```{r nopackageModel}


m_hyp_nopackage = glmer(Decision ~ varnum + used_fmriprep_data + fwhm + testing + movement_modeling + (1|teamID),
            data = hyp_df,family=binomial,
            control = glmerControl(optimizer ='optimx', 
                                   optCtrl=list(method='nlminb'))) 

anova_package <- anova(m_hyp_full,
                       m_hyp_nopackage,
                       test='Chisq')
print(anova_package)

leastsquare = emmeans(m_hyp_full,
                      'package')
multcomp::cld(leastsquare, 
    level=.05)

# compute delta r-squared between this model and full model
delta_r2_package <- r.squaredGLMM(m_hyp_full) - r.squaredGLMM(m_hyp_nopackage)
print(delta_r2_package)
```

#### Model without testing method

```{r notestingModel}
  
m_hyp_notesting = glmer(Decision ~ varnum + used_fmriprep_data + fwhm + package + movement_modeling + (1|teamID),
            data = hyp_df,family=binomial,
            control = glmerControl(optimizer ='optimx', 
                                   optCtrl=list(method='nlminb')))   

anova_testing <- anova(m_hyp_full,
                       m_hyp_notesting,test='Chisq')
print(anova_testing)

leastsquare = emmeans(m_hyp_full,
                      'testing')
multcomp::cld(leastsquare, 
    level=.05)

# compute delta r-squared between this model and full model
delta_r2_testing <- r.squaredGLMM(m_hyp_full) - r.squaredGLMM(m_hyp_notesting)
print(delta_r2_testing)
```

#### Model without movement modeling

```{r nomovementModel}
  
m_hyp_nomovement = glmer(Decision ~ varnum + used_fmriprep_data + fwhm + package  + testing + (1|teamID),
            data = hyp_df,family=binomial,
            control = glmerControl(optimizer ='optimx', 
                                   optCtrl=list(method='nlminb')))   

anova_testing <- anova(m_hyp_full,
                       m_hyp_nomovement,test='Chisq')
print(anova_testing)

# compute delta r-squared between this model and full model
delta_r2_movement <- r.squaredGLMM(m_hyp_full) - r.squaredGLMM(m_hyp_nomovement)
print(delta_r2_movement)
```

#### Applied vs. estimated smoothness

Full model using specified smoothing filter rather than estimated smoothness.

```{r kernelModel}
m_hyp_full_tsc = glmer(Decision ~ varnum + smoothing_coef + used_fmriprep_data + package + testing + movement_modeling + (1|teamID),
            data = hyp_df,family=binomial,
            control = glmerControl(optimizer ='optimx', 
                                   optCtrl=list(method='nlminb')))
summary(m_hyp_full_tsc)

```


### Separate analyses for each variable of interest

#### Hypothesis 

```{r varnum_only}
m_hyp_varnum = glmer(Decision ~ varnum + (1|teamID),
            data = hyp_df,family=binomial,
            control = glmerControl(optimizer ='optimx', 
                                   optCtrl=list(method='nlminb')))

summary_varnum <- summary(m_hyp_varnum)
print(summary_varnum)

```

#### Estimated smoothness

```{r fwhm_only}
m_hyp_fwhm = glmer(Decision ~ fwhm + (1|teamID),
            data = hyp_df,family=binomial,
            control = glmerControl(optimizer ='optimx', 
                                   optCtrl=list(method='nlminb')))

summary_fwhm <- summary(m_hyp_fwhm)
print(summary_fwhm)

```

#### Applied smoothing kernel

```{r kernel_only}
m_hyp_kernel = glmer(Decision ~ smoothing_coef + (1|teamID),
            data = hyp_df,family=binomial,
            control = glmerControl(optimizer ='optimx', 
                                   optCtrl=list(method='nlminb')))

summary_kernel <- summary(m_hyp_kernel)
print(summary_kernel)

```

#### fMRIprep

```{r fmriprep_only}
m_hyp_fmriprep = glmer(Decision ~ used_fmriprep_data + (1|teamID),
            data = hyp_df,family=binomial,
            control = glmerControl(optimizer ='optimx', 
                                   optCtrl=list(method='nlminb')))

summary_fmriprep <- summary(m_hyp_fmriprep)
print(summary_fmriprep)

```

#### Package

```{r package_only}
m_hyp_package = glmer(Decision ~ package  + (1|teamID),
            data = hyp_df,family=binomial,
            control = glmerControl(optimizer ='optimx', 
                                   optCtrl=list(method='nlminb')))

summary_package <- summary(m_hyp_package)
print(summary_package)

```

#### Testing

```{r testing_only}
m_hyp_testing = glmer(Decision ~ testing + (1|teamID),
            data = hyp_df,family=binomial,
            control = glmerControl(optimizer ='optimx', 
                                   optCtrl=list(method='nlminb')))

summary_testing <- summary(m_hyp_testing)
print(summary_testing)

```

### Separate analyses for each hypothesis

For each hypothesis, we ask whether decisions are associated with fwhm and use of fmriprep.  None of these survive Bonferroni correction.

```{r runModelsFunction}

runModels = function(hyp, data_df){
  pvals = c()

  m_hyp_full = bayesglm(Decision ~ fwhm + used_fmriprep_data + package + testing + movement_modeling,
                   data = data_df,family=binomial)
  
  m_hyp_nosmooth = bayesglm(Decision ~ used_fmriprep_data + package + testing,
                   data = data_df,family=binomial)
  #cat('testing effect of smoothing\n')
  a = anova(m_hyp_full,
            m_hyp_nosmooth,
            test='Chisq')
  pvals = c(pvals,unlist(a)['Pr(>Chi)2'])
  
  m_hyp_noprep = bayesglm(Decision ~ fwhm + package + testing,
                   data = data_df,family=binomial)
  #cat('testing effect of fmriprep\n')
  a=anova(m_hyp_full,m_hyp_noprep,test='Chisq')
  pvals = c(pvals,unlist(a)['Pr(>Chi)2'])
  
  m_hyp_nopackage = bayesglm(Decision ~ used_fmriprep_data + fwhm + testing,
                   data = data_df,family=binomial)
  #cat('testing effect of package\n')
  a=anova(m_hyp_full,
          m_hyp_nopackage,
          test='Chisq')
  pvals = c(pvals,unlist(a)['Pr(>Chi)2'])
  
  
  m_hyp_notesting = bayesglm(Decision ~ used_fmriprep_data + fwhm + package,
                   data = data_df,family=binomial)
  #cat('testing effect of testing\n')
  a=anova(m_hyp_full,
          m_hyp_notesting,
          test='Chisq')
  pvals = c(pvals,unlist(a)['Pr(>Chi)2'])
  return(pvals)
}
```


```{r runAllModels}
all_pvals = c()
for (hyp in 1:9){
  pv = runModels(hyp, hyp_df)
  all_pvals = rbind(all_pvals,pv)
}

```

### Assess consistency across packages

```{r}
var_by_package <- hyp_df %>% group_by(varnum, package) %>% summarize(varDecision = var(Decision))
var_model <- lm(varDecision ~ varnum + package, data = var_by_package)
var_model_nopackage <- lm(varDecision ~ varnum, data = var_by_package)
summary(var_model)
anova(var_model, var_model_nopackage)
emmeans(var_model,'package')

```

### Assess relation between smoothness and movement modeling

```{r smoothnessMovement}

smoothness_full = lmer(fwhm ~ varnum +  movement_modeling +  smoothing_coef + (1|teamID),
            data = hyp_df)

summary_smoothness <- summary(smoothness_full)
print(summary_smoothness)

```

### Examine effects of various factors on pattern distance

```{r loadPatternDistance}

patterndist_df = read_csv(paste(basedir,
          'metadata/median_pattern_corr.csv',
          sep='/'),skip=0)
names(patterndist_df)=c('teamID','median_corr')

merged_df = join(patterndist_df,narps_df %>% 
                   filter(varnum==1),by=c('teamID'))
```

### fit model

```{r r2z, echo=FALSE}
r2z = function(r){
    # fisher transform
    z=0.5*log((1.0+r)/(1.0-r))
    z[is.na(z)]=0
    return(z)
}
```

```{r fitPatternDistanceModel}

merged_df <- merged_df %>%
  mutate(z_median_corr = r2z(median_corr))

merged_df = merged_df %>% 
  drop_na(fwhm,used_fmriprep_data,package,testing)

dist_hyp_full = lm(z_median_corr ~ fwhm + used_fmriprep_data + package + testing + movement_modeling,
            data = merged_df)

s <- summary(dist_hyp_full)
print(s)

```

```{r fitnoSmoothDistanceModel}
dist_hyp_nosmooth <- lm(z_median_corr ~ used_fmriprep_data + package + testing + movement_modeling,
            data = merged_df)

anova(dist_hyp_full,
      dist_hyp_nosmooth,
      test='Chisq')

emtrends(dist_hyp_full,specs='fwhm',var='fwhm')
s$r.squared - summary(dist_hyp_nosmooth)$r.squared

```

```{r fitNoPrepDistanceModel}
dist_hyp_noprep = lm(z_median_corr ~ fwhm + package + testing + movement_modeling,
            data = merged_df)

anova(dist_hyp_full,
      dist_hyp_noprep,
      test='Chisq')

emmeans(dist_hyp_full,'used_fmriprep_data')
s$r.squared - summary(dist_hyp_noprep)$r.squared

```

```{r fitNoPackageDistanceModel}
dist_hyp_nopackage = lm(z_median_corr ~ used_fmriprep_data + fwhm + testing + movement_modeling,
            data = merged_df) 

anova(dist_hyp_full,
      dist_hyp_nopackage,
      test='Chisq')

s$r.squared - summary(dist_hyp_nopackage)$r.squared
leastsquare = emmeans(dist_hyp_full,'package')
multcomp::cld(leastsquare, 
    level=.05)


```

```{r fitNoTestingDistanceModel}
dist_hyp_notesting = lm(z_median_corr ~ used_fmriprep_data + fwhm + package + movement_modeling,
            data = merged_df)   

anova(dist_hyp_full,
      dist_hyp_notesting,
      test='Chisq')

s$r.squared - summary(dist_hyp_notesting)$r.squared

leastsquare = emmeans(dist_hyp_full,
                      'testing')

multcomp::cld(leastsquare, 
    level=.05)


```

```{r fitNoMovementDistanceModel}
dist_hyp_nomovement = lm(z_median_corr ~ used_fmriprep_data + fwhm + package + testing,
            data = merged_df)   

anova(dist_hyp_full,
      dist_hyp_nomovement,
      test='Chisq')

s$r.squared - summary(dist_hyp_nomovement)$r.squared


```

Make supplementary table 5

```{r mkSuppTable5}

df_SuppTable4 <- data.frame(
  Effects = c('Hypothesis', 
              'Smoothness', 
              'Used fMRIprep data', 
              'Software package', 
              'Multiple testing correction')) %>%
  mutate(ChiSquared = NA,
         Pvalue = NA,
         delta_r2 = NA)

df_SuppTable4[1,2:4] = c(anova_hyp$`Chisq`[2],
                         anova_hyp$`Pr(>Chisq)`[2],
                         delta_r2_hyp[2,1]
                         )
df_SuppTable4[2,2:4] = c(anova_smoothing$`Chisq`[2],
                         anova_smoothing$`Pr(>Chisq)`[2],
                         delta_r2_smoothing[2,1]
                         )
df_SuppTable4[3,2:4] = c(anova_fmriprep$`Chisq`[2],
                         anova_fmriprep$`Pr(>Chisq)`[2],
                         delta_r2_fmriprep[2,1]
                         )
df_SuppTable4[4,2:4] = c(anova_package$`Chisq`[2],
                         anova_package$`Pr(>Chisq)`[2],
                         delta_r2_package[2,1]
                         )
df_SuppTable4[5,2:4] = c(anova_testing$`Chisq`[2],
                         anova_testing$`Pr(>Chisq)`[2],
                         delta_r2_testing[2,1]
                         )

kable(df_SuppTable4)

write.table(df_SuppTable4,
            file=paste(basedir,"figures/SuppTable4.txt",sep='/'))

tab_latex = print(xtable(df_SuppTable4, 
             type = "latex", 
             digits=c(0,0,2,3,2)),
      floating=FALSE,
      latex.environments=NULL,
      booktabs=TRUE)

latex_preamble=c('\\documentclass[11pt, oneside]{article}',
'\\title{Supplementary Table 4}',
'\\date{}',
'\\usepackage{booktabs}',
'\\begin{document}',
'\\maketitle')

if (TRUE) {
fileConn<-file(paste(basedir,"figures/SuppTable4.tex",sep='/'))
writeLines(c(latex_preamble,tab_latex,c('\\end{document}')), fileConn)
#writeLines(tab_latex, fileConn)
close(fileConn)

# leave this out so that we don't have to install tex within docker
#texi2dvi(paste(basedir,"figures/SuppTable4.tex",sep='/'),
#         clean = TRUE)
}

```


```{r tmpCleanup}
if (use_checkpoint){
  unlink(checkpointDir, recursive = TRUE)
}
```

